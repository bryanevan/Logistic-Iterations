{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=('/Users/bryanevan/desktop/calidata.csv')\n",
    "df=pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'Population',\n",
       " 'Violent crime',\n",
       " 'Murder and nonnegligent manslaughter',\n",
       " 'Rape(revised definition)1',\n",
       " 'Rape(legacy definition)2',\n",
       " 'Robbery',\n",
       " 'Aggravated assault',\n",
       " 'Property crime',\n",
       " 'Burglary',\n",
       " 'Larceny-theft',\n",
       " 'Motor vehicle theft',\n",
       " 'Arson',\n",
       " 'Unnamed: 13']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=[i for i in list(df)]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.drop(['Unnamed: 13'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.drop(['Rape(revised definition)1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.rename(columns={'Violent crime': 'Violent_crime', 'Murder and nonnegligent manslaughter': 'Murder_manslaughter', 'Rape(legacy definition)2': 'Rape', 'Aggravated assault': 'Aggravated_assault', 'Property crime': 'Property_crime', 'Larceny-theft': 'Theft', 'Motor vehicle theft': 'GTA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Population=df1.Population.apply(lambda x: x.replace(',', '')).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Violent_crime=df1.Violent_crime.apply(lambda x: x.replace(',', '')).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Robbery=df1.Robbery.apply(lambda x: x.replace(',', '')).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Aggravated_assault=df1.Aggravated_assault.apply(lambda x: x.replace(',', '')).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Property_crime=df1.Property_crime.apply(lambda x: x.replace(',', '')).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Burglary=df1.Burglary.apply(lambda x: x.replace(',', '')).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Theft=df1.Theft.apply(lambda x: x.replace(',', '')).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.GTA=df1.GTA.apply(lambda x: x.replace(',', '')).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Arson=df1.Arson.apply(lambda x: x.replace(',', '')).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft=pd.get_dummies(df1)\n",
    "ft['killer'] = np.where(df1['Murder_manslaughter']>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['seeing_red'] = df1['Violent_crime'] * df1['Aggravated_assault']\n",
    "df1['affect'] = df1['Robbery'] * df1['Burglary']\n",
    "df1['boost'] = df1['GTA'] * df1['Theft']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      " [-7.63392398e-05]\n",
      "Coefficients: \n",
      " [[-1.25204242e-05 -2.92868088e-04 -1.13104648e-03 -9.93746762e-05\n",
      "   4.64982440e-05  1.95549215e-05  3.89783021e-05  1.32093947e-06]]\n",
      "\n",
      "R-squared:\n",
      "0.7489177489177489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df1[['Population', 'Robbery', 'Burglary', 'Arson', 'Rape', 'seeing_red', 'affect', 'boost']]\n",
    "y = ft['killer'].values.reshape(-1,1).ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "log = LogisticRegression(random_state=0, multi_class='auto', solver='lbfgs')\n",
    "log.fit(X_train, y_train)\n",
    "log.score(X_train, y_train)\n",
    "\n",
    "print('Intercept: \\n', log.intercept_)\n",
    "print('Coefficients: \\n', log.coef_)\n",
    "print('\\nR-squared:')\n",
    "print(log.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.83333333, 0.83333333, 0.66666667, 0.72222222,\n",
       "       0.77777778, 0.72222222, 0.55555556, 0.72222222, 0.76470588,\n",
       "       0.88235294, 0.64705882, 0.76470588, 0.88235294, 0.64705882,\n",
       "       0.76470588, 0.82352941, 0.625     , 0.625     , 0.8125    ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(log, X_train, y_train, cv=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      " 0.2709851018493517\n",
      "Coefficients: \n",
      " [ 2.16328165e-06  6.33354438e-05  8.97079261e-05  8.88704689e-04\n",
      "  2.84622553e-03 -8.54441087e-08  1.04037301e-07 -1.90345100e-08]\n",
      "\n",
      "R-squared:\n",
      "0.21238546692720983\n"
     ]
    }
   ],
   "source": [
    "ridgelog = linear_model.Ridge(alpha=9500, fit_intercept=True)\n",
    "ridgelog.fit(X_train, y_train)\n",
    "print('Intercept: \\n', ridgelog.intercept_)\n",
    "print('Coefficients: \\n', ridgelog.coef_)\n",
    "print('\\nR-squared:')\n",
    "print(ridgelog.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.42585556e-01,  1.86488248e-01,  1.52359809e-01,  1.20819493e-01,\n",
       "        9.52076681e-02, -2.10084936e+02, -5.81934673e-01, -7.08861575e-01,\n",
       "        1.32197834e-01, -1.09923378e+00])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(ridgelog, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      " 0.407587025329774\n",
      "Coefficients: \n",
      " [ 8.15384290e-07  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -5.30424215e-09 -0.00000000e+00 -2.00287937e-09]\n",
      "\n",
      "R-squared:\n",
      "0.08421969163992205\n"
     ]
    }
   ],
   "source": [
    "lasso = linear_model.Lasso(alpha = 9500)\n",
    "lassofit = lasso.fit(X_train,y_train)\n",
    "print('Intercept: \\n', lasso.intercept_)\n",
    "print('Coefficients: \\n', lasso.coef_)\n",
    "print('\\nR-squared:')\n",
    "print(lasso.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How likely is a population which has committed other kinds of crimes likely to commit murder: is a history of crime an indicator of a capacity to kill? Binary outcome variable is set to killer/ non-killer, where killer is defined as any data reflected in Murder_manslaughter.\n",
    "Feature selection was motivated by the nature of the data: only data reflecting a crime which requires the agent to be considerably aggressive to have committed the crime was selected. This is motivated by the nature of the outcome variable, committing murder; that is, given murder is the epitome of a personal violent act, and all data reflects individual instances of crime with in a given city, committing other belligerent crimes may serves as a fair indicator of oneâ€™s capacity to commit murder. Identical features are fed into all three models for consistency.\n",
    "Regularization parameter was determined by running CV with different settings, and evaluated by a cross-analysis of those varying settings within Ridge and Lasso regressions.\n",
    "\n",
    "For the effort of this exercise, Vanilla logistic stood out considerably; however, allow me first to say that Lasso is frankly far too aggressive for the amount of information being computed here: the amount of features selected was simply underwhelming for lasso. After having found a viable setting for lambda, Lasso shrunk nearly all of my parameters to zero. Secondly, Lasso generated a very unsatisfactory R-squared, which renders Lasso essentially useless for this exercise. Ridge didnâ€™t prove very useful here either, as R-squared was very low and CV was difficult to find consistency in. The stand-out is clearly Vanilla, but that was pretty evident from the beginning; moreover, this model was not very complex, had a small number of features, and showed no overfitting after running Vanilla; thus, it was overkill to do any modifications to Vanilla. If these conditions were not the case, it would have certainly been useful to use the more aggressive iterations of logistic regression, i.e., high multi-collinearity, increasingly large coefficients relative to intercept, or evident overfitting. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
